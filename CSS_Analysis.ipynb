{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import pickle\n",
    "import training\n",
    "import utilities\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import nltk\n",
    "import sklearn.metrics.pairwise\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "dataDir = 'data'\n",
    "modelsDir = 'models'\n",
    "\n",
    "rawFname = 'combined.csv'\n",
    "manualFname = None\n",
    "\n",
    "w2vFname = 'word2vec.bin'\n",
    "pickleFname = 'dfPickles.p'\n",
    "regenW2V = False\n",
    "\n",
    "eta = 0.001\n",
    "numEpochs = 50\n",
    "epochSize = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compareRows(rows, N, useTitle = True, w2v = None):\n",
    "    fig, axes = plt.subplots(figsize = (20,25),\n",
    "                             nrows = len(rows) + 1,\n",
    "                             gridspec_kw = {'height_ratios': [5] * len(rows) + [1]})\n",
    "    aLst = []\n",
    "    for i, row in enumerate(rows):\n",
    "        if 'title_vecs' in row:\n",
    "            abVec, tiVec, yVec = utilities.varsFromRow(row)\n",
    "        else:\n",
    "            abVec, tiVec, yVec = utilities.varsFromRow(row, w2v)\n",
    "        if useTitle:\n",
    "            outLSTM, (h_n, c_n) = N.lstmTi(tiVec)\n",
    "            s = row['title']\n",
    "        else:\n",
    "            outLSTM, (h_n, c_n) = N.lstmAb(abVec)\n",
    "            s = row['abstract']\n",
    "        out = N(abVec, tiVec)\n",
    "        probNeg = np.exp(out.data[0][0])\n",
    "        probPos = np.exp(out.data[0][1])            \n",
    "        probNeg = probNeg / (probNeg + probPos)\n",
    "        probPos = probPos / (probNeg + probPos)\n",
    "        \n",
    "        a = np.array(outLSTM.data.tolist())\n",
    "        aLst.append(a[0, -1, :])\n",
    "        #a = a[:,:100,:]\n",
    "        df = pandas.DataFrame(a[0, :, :])\n",
    "        df.index = nltk.word_tokenize(s)[:a.shape[1]]\n",
    "        seaborn.heatmap(df, ax = axes[i], label='big')\n",
    "        axes[i].set_title(\"Article Title: '{}'\\n$P_{{negative}} = {:.4f}, P_{{positive}} = {:.4f}$\".format(row['title'], probNeg, probPos), fontsize = 20)\n",
    "        axes[i].set_xticklabels([])\n",
    "        \n",
    "    \n",
    "    dfDiff = pandas.DataFrame(np.stack([aLst[0], np.fabs(aLst[0] - aLst[1]), aLst[1]]))\n",
    "    dfDiff.index = ['Top', 'Diff', 'Bottom']\n",
    "    seaborn.heatmap(dfDiff, ax = axes[-1], xticklabels = [i if i in np.linspace(0, len(dfDiff.columns) - 1, num = 10, dtype='int') else '' for i in range(len(dfDiff.columns))])\n",
    "    axes[-1].set_title('Difference in Final Output Vectors', fontsize = 20)\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wordDiff(df, N, useTitle = True, w2v = None):\n",
    "    wDiffs = {}\n",
    "    for i, (n, row) in enumerate(df.iterrows()):\n",
    "        print(\"{:.0f}% Done\".format(i / len(df) * 100), end = '\\r')\n",
    "        if 'title_vecs' in row:\n",
    "            abVec, tiVec, yVec = utilities.varsFromRow(row)\n",
    "        else:\n",
    "            abVec, tiVec, yVec = utilities.varsFromRow(row, w2v)\n",
    "        if useTitle:\n",
    "            outLSTM, (h_n, c_n) = N.lstmTi(tiVec)\n",
    "            s = row['title']\n",
    "        else:\n",
    "            outLSTM, (h_n, c_n) = N.lstmAb(abVec)\n",
    "            s = row['abstract']\n",
    "        if not isinstance(s, str):\n",
    "            continue\n",
    "        out = N(abVec, tiVec)\n",
    "        a = np.array(outLSTM.data.tolist())[0]\n",
    "        diffs = []\n",
    "        for i in range(a.shape[0]):\n",
    "            try:\n",
    "                dU = 1 - sklearn.metrics.pairwise.cosine_similarity(a[i - 1].reshape(1, -1), a[i].reshape(1, -1))\n",
    "            except IndexError:\n",
    "                dU = 0\n",
    "            try:\n",
    "                dD = 1 - sklearn.metrics.pairwise.cosine_similarity(a[i + 1].reshape(1, -1), a[i].reshape(1, -1))\n",
    "                if dU == 0:\n",
    "                    dU = dD\n",
    "            except IndexError:\n",
    "                dD = dU\n",
    "            diffs.append(np.mean([dU,dD]))\n",
    "            \n",
    "        for d, w in zip(diffs, nltk.word_tokenize(s.lower())):\n",
    "            if w in wDiffs:\n",
    "                wDiffs[w].append(d)\n",
    "            else:\n",
    "                wDiffs[w]= [d]\n",
    "    return {w : np.mean(d) for w, d in wDiffs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordDiffPlot(row, N, useTitle = True, w2v = None):\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    if 'title_vecs' in row:\n",
    "        abVec, tiVec, yVec = utilities.varsFromRow(row)\n",
    "    else:\n",
    "        abVec, tiVec, yVec = utilities.varsFromRow(row, w2v)\n",
    "    if useTitle:\n",
    "        outLSTM, (h_n, c_n) = N.lstmTi(tiVec)\n",
    "        s = row['title']\n",
    "    else:\n",
    "        outLSTM, (h_n, c_n) = N.lstmAb(abVec)\n",
    "        s = row['abstract']\n",
    "    out = N(abVec, tiVec)\n",
    "    a = np.array(outLSTM.data.tolist())[0]\n",
    "    diffs = []\n",
    "    for i in range(a.shape[0]):\n",
    "        try:\n",
    "            dU = 1 - sklearn.metrics.pairwise.cosine_similarity(a[i - 1].reshape(1, -1), a[i].reshape(1, -1))\n",
    "        except IndexError:\n",
    "            dU = 0\n",
    "        try:\n",
    "            dD = 1 - sklearn.metrics.pairwise.cosine_similarity(a[i + 1].reshape(1, -1), a[i].reshape(1, -1))\n",
    "            if dU == 0:\n",
    "                dU = dD\n",
    "        except IndexError:\n",
    "            dD = dU\n",
    "        diffs.append(np.mean([dU,dD]))\n",
    "    dfDiffs = pandas.DataFrame({'diff' : diffs})\n",
    "    #dfDiffs['loc'] = dfDiffs.index\n",
    "    dfDiffs.index = nltk.word_tokenize(s)\n",
    "    dfDiffs = dfDiffs#[1:-1]\n",
    "    dfDiffs.plot(ax = ax)\n",
    "    print(\"Done      \")\n",
    "    return dfDiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRNN-2-256-30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"models/BiRNN-2-256-30.pt\", 'rb') as f:\n",
    "    N = torch.load(f)\n",
    "N.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading W2V\n",
      "Loading DF\n",
      "Generating training and testing sets\n",
      "Generating word vectors\n"
     ]
    }
   ],
   "source": [
    "df, w2v = utilities.preprocesing(dataDir, rawFname, modelsDir, w2vFname, pickleFname)\n",
    "dfTrain, dfTest = utilities.getTrainTest(df, dataDir, None, w2v)\n",
    "df.index = df['eid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20307 total records\n"
     ]
    }
   ],
   "source": [
    "print('There are {} total records'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1491 total records\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 2000:\n",
    "    df = df[df['class'] == 0].sample(1000).append(df[df['class'] == 1])\n",
    "print('There are {} total records'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/withYears.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-de2540d917c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/withYears.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/withYears.csv'"
     ]
    }
   ],
   "source": [
    "dfY.to_csv('outputs/withYears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels [ nan] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-df7ba4ea1660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdfY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/withYears.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdfY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mdfY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isCSS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weightP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdfY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weightN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdfY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is CSS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isCSS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels [ nan] not contained in axis"
     ]
    }
   ],
   "source": [
    "regen = False\n",
    "if regen:\n",
    "    catsDict = {\n",
    "        'title' : [],\n",
    "        'eid' : [],\n",
    "        'abstract' : [],\n",
    "        'weightP' : [],\n",
    "        'weightN' : [],\n",
    "    }\n",
    "\n",
    "    tDF = df\n",
    "    for i, (r_index, row) in enumerate(tDF.iterrows()):\n",
    "        print(\"{:.3f}\".format(i / len(tDF)), end = '\\r')\n",
    "        try:\n",
    "            abVec, tiVec, yVec = utilities.varsFromRow(row, w2v)\n",
    "            out = N(abVec, tiVec)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(row['eid'])\n",
    "            continue\n",
    "        catsDict['weightN'].append(out.data[0][0])\n",
    "        catsDict['weightP'].append(out.data[0][1])\n",
    "        catsDict['title'].append(row['title'])\n",
    "        catsDict['eid'].append(row['eid'])\n",
    "        catsDict['abstract'].append(row['abstract'])\n",
    "        #catsDict['source'].append(row['source'])\n",
    "    dfY = pandas.DataFrame(catsDict)\n",
    "    df\n",
    "else:\n",
    "    dfY = pandas.read_csv('outputs/withYears.csv', index_col='eid')\n",
    "#dfY = dfY.drop(float('nan'))\n",
    "dfY['isCSS'] = dfY['weightP'] > dfY['weightN']\n",
    "dfY['is CSS'] = dfY['isCSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfYearCounts = dfY.groupby(['New software', 'pubyear'])['pubyear'].count()\n",
    "dfYearCounts = pandas.DataFrame({'True' : dfYearCounts.loc[True], 'False' : dfYearCounts.loc[False],'tot' : df.groupby(['pubyear'])['pubyear'].count()})\n",
    "dfYearCounts['ratio'] = dfYearCounts['True'] / dfYearCounts['tot']\n",
    "dfYearCounts[['tot', 'False', 'True', 'ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "x_offset = -0.12\n",
    "\n",
    "dfPlt = dfY.groupby(['New software', 'pubyear'])['pubyear'].count().unstack('New software')\n",
    "dfPlt.plot(kind='bar', ax = ax)#, stacked=True)\n",
    "ax.set_ylabel('Count', fontsize=16)\n",
    "ax.set_xlabel('Year of Publication', fontsize=16)\n",
    "for p in ax.patches:\n",
    "    b = p.get_bbox()\n",
    "    val = \"{:.0f}\".format(b.y1 + b.y0)        \n",
    "    ax.annotate(val, ((b.x0 + b.x1)/2 + x_offset, b.y1 +100))\n",
    "ax.set_title('Year vs Number of Publications from each Class', fontsize=20)\n",
    "#plt.savefig('images/countvyear.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "df2 = dfY.groupby(['New software', 'source'])['source'].count().unstack('New software')\n",
    "df2 = df2#[df2[True] > 0]\n",
    "df2.index = [\"{}\\n{}\".format(' '.join(s.split(' ')[:4]), ' '.join(s.split(' ')[4:])) for s in df2.index]\n",
    "df2.sort_values(by=True,ascending=False).plot(kind='line', ax = ax, colormap= \"RdBu\")\n",
    "ax.set_ylabel('Count', fontsize=16)\n",
    "ax.set_xlabel('Publication', fontsize=16)\n",
    "#ax.xticks = [s if i % 2 ==0 else '' for i, s in enumerate(df2.index)]\n",
    "ax.set_title('Publication vs Number from Each Class', fontsize=20)\n",
    "#plt.savefig('images/countvyear.pdf', format='pdf')\n",
    "fig.autofmt_xdate()\n",
    "ax.semilogy()\n",
    "plt.savefig('images/countvpub.pdf', format='pdf', transparent = False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tJ = [\n",
    "    'STATISTICAL METHODS IN MEDICAL RESEARCH',\n",
    "    'JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B-STATISTICAL METHODOLOGY',\n",
    "    'ECONOMETRICA',\n",
    "    'BRITISH JOURNAL OF MATHEMATICAL & STATISTICAL PSYCHOLOGY',\n",
    "    'ANNUAL REVIEW OF STATISTICS AND ITS APPLICATION',\n",
    "    'ANNALS OF STATISTICS',\n",
    "    'STOCHASTIC ENVIRONMENTAL RESEARCH AND RISK ASSESSMENT',\n",
    "    'TECHNOMETRICS',\n",
    "]\n",
    "dfSourceCounts = dfY.groupby(['isSoftware', 'source']).size()\n",
    "dfSourceCounts.loc[False].sort_values(ascending=False)[tJ]#.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1 = df.loc['WOS:000272110900028']\n",
    "r2 = df.loc['WOS:000280216700014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY[dfY['isSoftware'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "r1 = df.loc['WOS:000365978900001']\n",
    "r2 = df.loc['WOS:000207446800001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#row = df.loc['WOS:000272110900028']\n",
    "print(\"r1\")\n",
    "print(r1['title'])\n",
    "print()\n",
    "print(r1['abstract'])\n",
    "print(r1['pubyear'])\n",
    "print(\"\\nr2\")\n",
    "print(r2['title'])\n",
    "print()\n",
    "print(r2['abstract'])\n",
    "print(r2['pubyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compareRows([r1, r2],N, w2v = w2v)\n",
    "plt.savefig('images/comparisonTitle.pdf', format  = 'pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compareRows([r1, r2],N, useTitle=False, w2v = w2v)\n",
    "plt.savefig('images/comparisonAbstract.pdf', format  = 'pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfDiffs= wordDiffPlot(r1, N, useTitle = False, w2v = w2v)\n",
    "plt.show()\n",
    "dfDiffs= wordDiffPlot(r2, N, useTitle = False, w2v = w2v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "langs = ['c', 'c++', 'python', 'stata', 'matlab', 'r', 'java', 'mathematica', 'sas', 'spss', 'javascript', 'perl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idsPython = [w for w, a, t in zip(dfY.index, dfY['abstract'], dfY['title']) if 'python' in (t + ' ' + a).lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "langCounts = {}\n",
    "for j, (i, row) in enumerate(df.iterrows()):\n",
    "    print(j, end = '\\r')\n",
    "    tokens = row['abstract_tokens'] + row['title_tokens']\n",
    "    try:\n",
    "        if dfY.loc[i]['isSoftware']:\n",
    "            for l in langs:\n",
    "                if l in tokens:\n",
    "                    try:\n",
    "                        langCounts[l].append(i)\n",
    "                    except KeyError:\n",
    "                        langCounts[l] = [i]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfC = dfY.loc[langCounts['c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = []\n",
    "count = []\n",
    "for k, v in langCounts.items():\n",
    "    index.append(k)\n",
    "    count.append(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfL = pandas.DataFrame({'count' : count}, index = [i.title() for i in index]).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dfL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texNames = [\n",
    "    ('Unnamed: 0', 'ID'),\n",
    "    ('source' , 'Source'),\n",
    "    ('pubyear' , 'Year of Publications'),\n",
    "    ('title' , 'Title'),\n",
    "    ('abstract' , 'Abstract'),\n",
    "    ]\n",
    "\n",
    "def rowToTex(row, cutoff = 70):\n",
    "    print(r\"\"\"\\begin{figure}[H]\n",
    "\t\\begin{tabular}{ll}\n",
    "\t\t\\toprule\n",
    "\t\tField & Value\\\\\n",
    "\t\t\\midrule\"\"\")\n",
    "    for rN, tN in texNames:\n",
    "        if len(str(row[rN])) < cutoff:\n",
    "            print('\\t\\t{} & {} \\\\\\\\'.format(tN, row[rN]))\n",
    "        else:\n",
    "            s = str(row[rN])\n",
    "            ts = s.split(' ')\n",
    "            sOut = ['']\n",
    "            while len(ts) > 0:\n",
    "                subT = ts.pop(0)\n",
    "                if len(sOut[-1] + ' ' + subT) < cutoff:\n",
    "                    sOut[-1] += ' ' + subT\n",
    "                else:\n",
    "                    sOut.append(subT)\n",
    "            print('\\t\\t{} & {} \\\\\\\\'.format(tN, '\\\\\\\\\\n\\t\\t&'.join(sOut)))\n",
    "    print(r\"\"\"\t\t\\bottomrule\n",
    "\t\\end{tabular}\n",
    "\\end{figure}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(w2v.wv.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rExample = dfY.loc['WOS:000341806800001']\n",
    "rowToTex(rExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{k : len(v) for k, v in langCounts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY[dfY['source'] == 'JOURNAL OF STATISTICAL SOFTWARE'][dfY['isSoftware'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY.loc['WOS:000292681800006']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wD = wordDiff(df[:100], N, useTitle = False, w2v = w2v)\n",
    "indices = []\n",
    "vals = []\n",
    "for k, v in wD.items():\n",
    "    indices.append(k)\n",
    "    vals.append(v)\n",
    "\n",
    "dfDiffs = pandas.DataFrame({'diff' : vals})\n",
    "dfDiffs.index = indices\n",
    "dfDiffs.sort_values('diff',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "dfY.plot.scatter('weightP', 'weightN', ax = ax)\n",
    "ax.set_ylabel('$log(P_{Negative})$')\n",
    "ax.set_xlabel('$log(P_{Positive})$')\n",
    "ax.set_title('Output log Probability of Negative vs Positive')\n",
    "plt.savefig('images/weight.pdf', format = 'pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Loading W2V\n",
    "Loading DF\n",
    "Generating training and testing sets\n",
    "Generating word vectors\n",
    "Enriching training set\n",
    "Training: 2216 postive, 3944 negative, 0.360 percent\n",
    "Testing: 143 postive, 418 negative, 0.255 percent\n",
    "Epoch 0, loss 0.589, error 0.255, detectionRate 0.000, falseP 0.000\n",
    "Epoch 1, loss 0.363, error 0.185, detectionRate 1.000, falseP 0.249\n",
    "Epoch 2, loss 0.141, error 0.041, detectionRate 0.916, falseP 0.026\n",
    "Epoch 3, loss 0.172, error 0.043, detectionRate 0.937, falseP 0.036\n",
    "Epoch 4, loss 0.162, error 0.055, detectionRate 0.965, falseP 0.062\n",
    "Epoch 5, loss 0.129, error 0.032, detectionRate 0.944, falseP 0.024\n",
    "Epoch 6, loss 0.158, error 0.059, detectionRate 0.958, falseP 0.065\n",
    "Epoch 7, loss 0.123, error 0.030, detectionRate 0.937, falseP 0.019\n",
    "Epoch 8, loss 0.123, error 0.032, detectionRate 0.958, falseP 0.029\n",
    "Epoch 9, loss 0.110, error 0.034, detectionRate 0.923, falseP 0.019\n",
    "Epoch 10, loss 0.128, error 0.034, detectionRate 0.944, falseP 0.026\n",
    "Epoch 11, loss 0.113, error 0.029, detectionRate 0.944, falseP 0.019\n",
    "Epoch 12, loss 0.134, error 0.048, detectionRate 0.972, falseP 0.055\n",
    "Epoch 13, loss 0.177, error 0.032, detectionRate 0.895, falseP 0.007\n",
    "Epoch 14, loss 0.129, error 0.030, detectionRate 0.916, falseP 0.012\n",
    "Epoch 15, loss 0.131, error 0.043, detectionRate 0.881, falseP 0.017\n",
    "Epoch 16, loss 0.176, error 0.068, detectionRate 0.944, falseP 0.072\n",
    "Epoch 17, loss 0.178, error 0.057, detectionRate 0.951, falseP 0.060\n",
    "Epoch 18, loss 0.149, error 0.059, detectionRate 0.846, falseP 0.026\n",
    "Epoch 19, loss 0.177, error 0.061, detectionRate 0.811, falseP 0.017\n",
    "Epoch 20, loss 0.124, error 0.032, detectionRate 0.923, falseP 0.017\n",
    "Epoch 21, loss 0.126, error 0.025, detectionRate 0.951, falseP 0.017\n",
    "Epoch 22, loss 0.121, error 0.030, detectionRate 0.909, falseP 0.010\n",
    "Epoch 23, loss 0.115, error 0.027, detectionRate 0.937, falseP 0.014\n",
    "Epoch 24, loss 0.245, error 0.057, detectionRate 0.832, falseP 0.019\n",
    "Epoch 25, loss 0.233, error 0.062, detectionRate 0.790, falseP 0.012\n",
    "Epoch 26, loss 0.148, error 0.043, detectionRate 0.860, falseP 0.010\n",
    "Epoch 27, loss 0.127, error 0.034, detectionRate 0.916, falseP 0.017"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Loading DFs\n",
    "1269 postive\n",
    "7790 negative\n",
    "Epoch 0, loss 0.433, error 0.105, detectionRate 0.784, falseP 0.074\n",
    "Epoch 1, loss 0.387, error 0.203, detectionRate 0.063, falseP 0.001\n",
    "Epoch 2, loss 0.544, error 0.129, detectionRate 0.887, falseP 0.133\n",
    "Epoch 3, loss 0.155, error 0.050, detectionRate 0.788, falseP 0.006\n",
    "Epoch 4, loss 0.126, error 0.041, detectionRate 0.856, falseP 0.012\n",
    "Epoch 5, loss 0.123, error 0.040, detectionRate 0.937, falseP 0.033\n",
    "Epoch 6, loss 0.102, error 0.035, detectionRate 0.883, falseP 0.012\n",
    "Epoch 7, loss 0.105, error 0.036, detectionRate 0.941, falseP 0.030\n",
    "Epoch 8, loss 0.093, error 0.023, detectionRate 0.955, falseP 0.017\n",
    "Epoch 9, loss 0.115, error 0.040, detectionRate 0.973, falseP 0.043\n",
    "Epoch 10, loss 0.091, error 0.028, detectionRate 0.955, falseP 0.023\n",
    "Epoch 11, loss 0.090, error 0.029, detectionRate 0.937, falseP 0.020\n",
    "Epoch 12, loss 0.088, error 0.031, detectionRate 0.892, falseP 0.010\n",
    "Epoch 13, loss 0.086, error 0.024, detectionRate 0.946, falseP 0.016\n",
    "Epoch 14, loss 0.088, error 0.028, detectionRate 0.959, falseP 0.025\n",
    "Epoch 15, loss 0.078, error 0.025, detectionRate 0.946, falseP 0.017\n",
    "Epoch 16, loss 0.083, error 0.025, detectionRate 0.914, falseP 0.009\n",
    "Epoch 17, loss 0.105, error 0.023, detectionRate 0.896, falseP 0.001\n",
    "Epoch 18, loss 0.080, error 0.025, detectionRate 0.959, falseP 0.021\n",
    "Epoch 19, loss 0.075, error 0.025, detectionRate 0.937, falseP 0.015\n",
    "^CExiting and saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
